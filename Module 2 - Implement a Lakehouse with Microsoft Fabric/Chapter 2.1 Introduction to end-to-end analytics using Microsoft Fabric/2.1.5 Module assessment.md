# **Knowledge Check: Solutions**

#### **Question 1: What is a key benefit of using Microsoft Fabric in data projects?**

<div align="center">
<svg width="100" height="80" viewBox="0 0 100 80" fill="none" xmlns="http://www.w3.org/2000/svg">
<circle cx="50" cy="40" r="25" fill="#E3F2FD" stroke="#1E88E5" stroke-width="2"/>
<circle cx="50" cy="25" r="5" fill="#BBDEFB"/>
<circle cx="35" cy="50" r="5" fill="#BBDEFB"/>
<circle cx="65" cy="50" r="5" fill="#BBDEFB"/>
<path d="M50 30 L 50 35 M40 48 L 45 42 M60 48 L 55 42" stroke="#1976D2" stroke-width="1.5"/>
</svg>
</div>

*   A. It allows data professionals to work independently, without collaboration.
*   B. It requires duplicating data across systems to ensure availability.
*   **C. It provides a single, integrated environment for collaboration on data projects.**

> [!SUCCESS]
> **Correct Answer: C**
>
> **Explanation:** The fundamental value proposition of Microsoft Fabric is its ability to unify the entire analytics lifecycle on a single platform. It breaks down the traditional silos between data engineers, data scientists, analysts, and business users by providing a shared data foundation (OneLake) and integrated tools. This fosters seamless collaboration, reduces friction between teams, and accelerates the time from data to insight.

#### **Question 2: What is the default storage format for Fabric's OneLake?**

<div align="center">
<svg width="100" height="80" viewBox="0 0 100 80" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M25 60 L 50 70 L 75 60 L 50 50 Z" fill="#B2DFDB"/>
<path d="M25 45 L 50 55 L 75 45 L 50 35 Z" fill="#80CBC4"/>
<path d="M25 30 L 50 40 L 75 30 L 50 20 Z" fill="#4DB6AC" stroke="#004D40" stroke-width="2"/>
</svg>
</div>

*   **A. Delta-Parquet**
*   B. JSON
*   C. CSV

> [!SUCCESS]
> **Correct Answer: A**
>
> **Explanation:** OneLake, the unified data lake for Microsoft Fabric, standardizes on the **Delta-Parquet** format. This open-source format combines the high-performance, columnar storage of Parquet with the reliability and transactional capabilities of Delta Lake. This provides critical features like ACID transactions (atomicity, consistency, isolation, durability), time travel (versioning), and schema enforcement directly on the data lake, which is essential for building a reliable Lakehouse architecture.


#### **Question 3: Which Fabric experience is used to move and transform data?**

<div align="center">
<svg width="100" height="80" viewBox="0 0 100 80" fill="none" xmlns="http://www.w3.org/2000/svg">
<rect x="10" y="30" width="20" height="20" rx="3" fill="#E1F5FE" stroke="#0288D1" stroke-width="2"/>
<path d="M35 40 L 65 40" stroke="#546E7A" stroke-width="3" stroke-dasharray="4 2"/>
<path d="M60 35 L 70 40 L 60 45" fill="none" stroke="#546E7A" stroke-width="3"/>
<rect x="70" y="30" width="20" height="20" rx="3" fill="#E8F5E9" stroke="#2E7D32" stroke-width="2"/>
</svg>
</div>

*   A. Data Science
*   B. Data Warehousing
*   **C. Data Factory**

> [!SUCCESS]
> **Correct Answer: C**
>
> **Explanation:** **Data Factory** is the primary data integration service within Microsoft Fabric. It provides the tools necessary to ingest, move, and transform data from a wide variety of sources. Its two main components are:
> *   **Dataflows Gen2:** A low-code, visual experience (Power Query) for complex data transformations (ETL).
> *   **Data Pipelines:** An orchestration service to automate and schedule data movement and processing workflows.

