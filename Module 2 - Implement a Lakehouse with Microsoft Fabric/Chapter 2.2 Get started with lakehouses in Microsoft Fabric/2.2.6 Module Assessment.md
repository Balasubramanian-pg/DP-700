# **Knowledge Check: Microsoft Fabric Lakehouse**

#### **1. When designing an ETL process for a Microsoft Fabric lakehouse, which tool can be used to visually represent transformations without traditional programming?**

<div align="center">
<svg width="100" height="80" viewBox="0 0 100 80" fill="none" xmlns="http://www.w3.org/2000/svg">
<rect x="10" y="30" width="20" height="20" rx="3" fill="#E1F5FE" stroke="#0288D1" stroke-width="2"/>
<path d="M35 40 L 65 40" stroke="#546E7A" stroke-width="3" stroke-dasharray="4 2"/>
<path d="M60 35 L 70 40 L 60 45" fill="none" stroke="#546E7A" stroke-width="3"/>
<rect x="70" y="30" width="20" height="20" rx="3" fill="#FFF8E1" stroke="#F57F17" stroke-width="2"/>
</svg>
</div>

> [!TIP]
> **Answer: Dataflows Gen2**
>
> **Explanation:** Dataflows Gen2 are built on the Power Query engine, providing a powerful low-code/no-code interface for designing complex ETL transformations visually. This empowers data analysts and citizen developers to perform sophisticated data preparation without writing code, dramatically accelerating the development process.

#### **2. During an ETL process, which step is crucial after ingesting data into a lakehouse to ensure data quality and consistency?**

<div align="center">
<svg width="100" height="80" viewBox="0 0 100 80" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M20 20 L 40 40 L 20 60 L 40 80" stroke="#A7E6FF" stroke-width="3" stroke-linecap="round"/>
<rect x="45" y="15" width="10" height="70" rx="2" fill="#0078D4"/>
<path d="M65 20 L 85 20 M65 40 L 85 40 M65 60 L 85 60" stroke="#005A9E" stroke-width="3" stroke-linecap="round"/>
</svg>
</div>

> [!TIP]
> **Answer: Data transformation**
>
> **Explanation:** Raw data is rarely ready for analysis. The **transformation** step is where the data is cleaned, validated, standardized, and enriched. This crucial process ensures that the data loaded into the final tables is accurate, consistent, and trustworthy, which is the foundation for reliable analytics and business intelligence.

#### **3. How does a Microsoft Fabric lakehouse differ from a typical data lake in terms of data processing capabilities?**

<div align="center">
<svg width="100" height="80" viewBox="0 0 100 80" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M5 40 C 15 30, 25 30, 35 40 S 45 50, 55 40" stroke="#0078D4" stroke-width="2.5" fill="none"/>
<rect x="65" y="30" width="30" height="20" rx="3" fill="#E8F5E9" stroke="#2E7D32" stroke-width="2.5"/>
<path d="M45 40 L 60 40" stroke="#78909C" stroke-width="2"/>
<path d="M50 35 V 45" stroke="#78909C" stroke-width="2"/>
</svg>
</div>

> [!TIP]
> **Answer: Lakehouses integrate SQL and Spark engines for advanced data processing.**
>
> **Explanation:** A traditional data lake is primarily a storage repository. A Fabric Lakehouse evolves this concept by layering powerful compute engines directly on top of the data. This integration allows you to run high-performance SQL queries for BI and analytics *and* use Apache Spark for large-scale data engineering and machine learning, all on the same copy of the data.

#### **4. Which Microsoft Fabric component allows you to integrate external data into your lakehouse while keeping it stored in its original location?**

<div align="center">
<svg width="100" height="80" viewBox="0 0 100 80" fill="none" xmlns="http://www.w3.org/2000/svg">
<rect x="20" y="50" width="30" height="20" rx="3" fill="#E0F2F1" stroke="#00695C" stroke-width="2"/>
<path d="M40 40 L 60 40 L 60 20" stroke="#00897B" stroke-width="3" stroke-dasharray="3 3" fill="none"/>
<path d="M55 15 L 60 20 L 65 15" stroke="#00897B" stroke-width="3" fill="none" stroke-linecap="round" stroke-linejoin="round"/>
<rect x="65" y="50" width="15" height="20" rx="3" fill="#E0F2F1" stroke="#00695C" stroke-width="2"/>
</svg>
</div>

> [!TIP]
> **Answer: Shortcuts**
>
> **Explanation:** Shortcuts are a powerful feature of OneLake that act as symbolic links to data stored in external locations (like Azure Data Lake Storage Gen2 or Amazon S3). This allows you to query and analyze external data as if it were stored directly in your Lakehouse, without the cost, complexity, and latency of copying or moving it.

#### **5. What is a significant benefit of schema-on-read in Microsoft Fabric lakehouses compared to predefined schemas in traditional data warehouses?**

<div align="center">
<svg width="100" height="80" viewBox="0 0 100 80" fill="none" xmlns="http://www.w3.org/2000/svg">
<text x="30" y="50" font-family="monospace" font-size="30" fill="#78909C">?</text>
<path d="M50 40 L 70 40" stroke="#78909C" stroke-width="3" stroke-dasharray="3 3"/>
<path d="M65 35 L 75 40 L 65 45" fill="none" stroke="#78909C" stroke-width="3"/>
<rect x="75" y="30" width="20" height="20" rx="2" fill="#E8F5E9" stroke="#2E7D32" stroke-width="2"/>
</svg>
</div>

> [!TIP]
> **Answer: Schema-on-read allows for more flexible data ingestion and transformation.**
>
> **Explanation:** Traditional data warehouses use a rigid "schema-on-write" approach, where data must conform to a predefined structure *before* it can be loaded. Lakehouses use "schema-on-read," allowing you to ingest raw data in its native format. You apply a schema or structure only when you query the data, providing immense flexibility to handle evolving data sources and diverse data types without ingestion failures.

#### **6. Which feature of Microsoft Fabric lakehouses supports machine learning and predictive modeling analytics?**

<div align="center">
<svg width="100" height="80" viewBox="0 0 100 80" fill="none" xmlns="http://www.w3.org/2000/svg">
<circle cx="50" cy="40" r="20" fill="#F3E5F5" stroke="#7B1FA2" stroke-width="2"/>
<path d="M42 40 L 50 32 L 58 40 L 50 48 Z" fill="#E1BEE7" stroke="#7B1FA2" stroke-width="1.5"/>
<path d="M50 32 V 25 M 50 48 V 55 M 42 40 H 35 M 58 40 H 65" stroke="#7B1FA2" stroke-width="1.5" stroke-linecap="round"/>
</svg>
</div>

> [!TIP]
> **Answer: Spark and SQL engines**
>
> **Explanation:** The integrated Apache Spark engine is the cornerstone for machine learning in Fabric. It provides the distributed computing power necessary to process large datasets and train complex ML models using languages like Python and R. The SQL engine complements this by allowing for fast, efficient querying and feature engineering on the prepared data.

#### **7. Your organization wants to combine structured transaction data with social media feeds for analysis. Why might a Microsoft Fabric lakehouse be more suitable than a traditional data warehouse?**

<div align="center">
<svg width="100" height="80" viewBox="0 0 100 80" fill="none" xmlns="http://www.w3.org/2000/svg">
<rect x="15" y="30" width="15" height="20" rx="2" fill="#E8F5E9" stroke="#2E7D32" stroke-width="2"/>
<text x="40" y="45" font-family="monospace" font-size="12" fill="#0288D1">{...}</text>
<text x="70" y="45" font-family="monospace" font-size="12" fill="#F57F17">"abc"</text>
</svg>
</div>

> [!TIP]
> **Answer: Lakehouses can store all data formats and support SQL-based analytics.**
>
> **Explanation:** This scenario highlights the core strength of the lakehouse. A traditional warehouse would struggle with the semi-structured (JSON from social media) and unstructured (text) data. A lakehouse, however, is designed to store this variety of data in its native format while still providing a powerful SQL endpoint to query both the structured transaction data and the newly ingested feeds in a unified way.

#### **8. Which component in Microsoft Fabric lakehouse architecture is responsible for orchestrating ETL processes?**

<div align="center">
<svg width="100" height="80" viewBox="0 0 100 80" fill="none" xmlns="http://www.w3.org/2000/svg">
<rect x="5" y="35" width="20" height="10" rx="2" fill="#FCE4EC" stroke="#C2185B" stroke-width="2"/>
<path d="M25 40 L 45 40" stroke="#78909C" stroke-width="2"/>
<rect x="45" y="35" width="20" height="10" rx="2" fill="#FCE4EC" stroke="#C2185B" stroke-width="2"/>
<path d="M65 40 L 85 40" stroke="#78909C" stroke-width="2"/>
<rect x="85" y="35" width="10" height="10" rx="2" fill="#FCE4EC" stroke="#C2185B" stroke-width="2"/>
</svg>
</div>

> [!TIP]
> **Answer: Data Factory pipelines**
>
> **Explanation:** While Dataflows handle the transformation logic, **Data Factory pipelines** are the orchestrators. They are responsible for defining the workflow, scheduling the execution, managing dependencies between tasks (e.g., "run this dataflow, and if it succeeds, run this notebook"), and handling error logging and retries for the entire end-to-end process.

#### **9. Your organization plans to train machine learning models using data from a Microsoft Fabric lakehouse. Which tool is most appropriate for performing this task?**

<div align="center">
<svg width="100" height="80" viewBox="0 0 100 80" fill="none" xmlns="http://www.w3.org/2000/svg">
<rect x="25" y="20" width="50" height="40" rx="4" fill="#FBE9E7" stroke="#D84315" stroke-width="2"/>
<path d="M35 32 L 45 40 L 35 48" stroke="#BF360C" stroke-width="2.5" stroke-linecap="round" stroke-linejoin="round"/>
<path d="M50 50 H 70" stroke="#BF360C" stroke-width="2.5" stroke-linecap="round"/>
</svg>
</div>

> [!TIP]
> **Answer: Notebooks**
>
> **Explanation:** Notebooks are the standard interactive development environment for data science and machine learning. In Fabric, they provide a rich, cell-based interface where data scientists can write and execute Python, R, or Scala code, explore data with visualizations, leverage powerful libraries (like scikit-learn and TensorFlow), and document their experiments in a single, collaborative document.
